{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edba2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f4a25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-20 17:27:00</td>\n",
       "      <td>2023-02-20 17:49:00</td>\n",
       "      <td>40.808941</td>\n",
       "      <td>-73.914482</td>\n",
       "      <td>40.807336</td>\n",
       "      <td>-73.905270</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.84$</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28 19:41:00</td>\n",
       "      <td>2023-02-28 20:07:00</td>\n",
       "      <td>40.685842</td>\n",
       "      <td>-73.855449</td>\n",
       "      <td>40.663358</td>\n",
       "      <td>-73.826745</td>\n",
       "      <td>4.02</td>\n",
       "      <td>15.6£</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-14 08:37:00</td>\n",
       "      <td>2023-02-14 09:07:00</td>\n",
       "      <td>40.668055</td>\n",
       "      <td>-74.045050</td>\n",
       "      <td>40.642572</td>\n",
       "      <td>-74.055617</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2192.65¥</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-16 23:54:00</td>\n",
       "      <td>2023-01-17 00:40:00</td>\n",
       "      <td>40.765394</td>\n",
       "      <td>-73.753324</td>\n",
       "      <td>40.775285</td>\n",
       "      <td>-73.775441</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-11 01:16:00</td>\n",
       "      <td>2023-02-11 01:35:00</td>\n",
       "      <td>40.815841</td>\n",
       "      <td>-73.727328</td>\n",
       "      <td>40.836115</td>\n",
       "      <td>-73.746976</td>\n",
       "      <td>3.11</td>\n",
       "      <td>13.7€</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup_datetime     dropoff_datetime  pickup_latitude  \\\n",
       "0  2023-02-20 17:27:00  2023-02-20 17:49:00        40.808941   \n",
       "1  2023-02-28 19:41:00  2023-02-28 20:07:00        40.685842   \n",
       "2  2023-02-14 08:37:00  2023-02-14 09:07:00        40.668055   \n",
       "3  2023-01-16 23:54:00  2023-01-17 00:40:00        40.765394   \n",
       "4  2023-02-11 01:16:00  2023-02-11 01:35:00        40.815841   \n",
       "\n",
       "   pickup_longitude  dropoff_latitude  dropoff_longitude  trip_distance_miles  \\\n",
       "0        -73.914482         40.807336         -73.905270                 1.03   \n",
       "1        -73.855449         40.663358         -73.826745                 4.02   \n",
       "2        -74.045050         40.642572         -74.055617                 3.04   \n",
       "3        -73.753324         40.775285         -73.775441                 2.67   \n",
       "4        -73.727328         40.836115         -73.746976                 3.11   \n",
       "\n",
       "  fare_amount  passenger_count payment_type  \n",
       "0       5.84$              5.0  Credit Card  \n",
       "1       15.6£              4.0      Unknown  \n",
       "2    2192.65¥              5.0  Credit Card  \n",
       "3           0              4.0  Credit Card  \n",
       "4       13.7€              3.0  Credit Card  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NYC_Taxi_dataset_with_anomalies.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c06da33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-20 17:27:00</td>\n",
       "      <td>2023-02-20 17:49:00</td>\n",
       "      <td>40.808941</td>\n",
       "      <td>-73.914482</td>\n",
       "      <td>40.807336</td>\n",
       "      <td>-73.905270</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.84$</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28 19:41:00</td>\n",
       "      <td>2023-02-28 20:07:00</td>\n",
       "      <td>40.685842</td>\n",
       "      <td>-73.855449</td>\n",
       "      <td>40.663358</td>\n",
       "      <td>-73.826745</td>\n",
       "      <td>4.02</td>\n",
       "      <td>15.6£</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-14 08:37:00</td>\n",
       "      <td>2023-02-14 09:07:00</td>\n",
       "      <td>40.668055</td>\n",
       "      <td>-74.045050</td>\n",
       "      <td>40.642572</td>\n",
       "      <td>-74.055617</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2192.65¥</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-16 23:54:00</td>\n",
       "      <td>2023-01-17 00:40:00</td>\n",
       "      <td>40.765394</td>\n",
       "      <td>-73.753324</td>\n",
       "      <td>40.775285</td>\n",
       "      <td>-73.775441</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-11 01:16:00</td>\n",
       "      <td>2023-02-11 01:35:00</td>\n",
       "      <td>40.815841</td>\n",
       "      <td>-73.727328</td>\n",
       "      <td>40.836115</td>\n",
       "      <td>-73.746976</td>\n",
       "      <td>3.11</td>\n",
       "      <td>13.7€</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup_datetime     dropoff_datetime  pickup_latitude  \\\n",
       "0  2023-02-20 17:27:00  2023-02-20 17:49:00        40.808941   \n",
       "1  2023-02-28 19:41:00  2023-02-28 20:07:00        40.685842   \n",
       "2  2023-02-14 08:37:00  2023-02-14 09:07:00        40.668055   \n",
       "3  2023-01-16 23:54:00  2023-01-17 00:40:00        40.765394   \n",
       "4  2023-02-11 01:16:00  2023-02-11 01:35:00        40.815841   \n",
       "\n",
       "   pickup_longitude  dropoff_latitude  dropoff_longitude  trip_distance_miles  \\\n",
       "0        -73.914482         40.807336         -73.905270                 1.03   \n",
       "1        -73.855449         40.663358         -73.826745                 4.02   \n",
       "2        -74.045050         40.642572         -74.055617                 3.04   \n",
       "3        -73.753324         40.775285         -73.775441                 2.67   \n",
       "4        -73.727328         40.836115         -73.746976                 3.11   \n",
       "\n",
       "  fare_amount  passenger_count payment_type  \n",
       "0       5.84$              5.0  Credit Card  \n",
       "1       15.6£              4.0      Unknown  \n",
       "2    2192.65¥              5.0  Credit Card  \n",
       "3           0              4.0  Credit Card  \n",
       "4       13.7€              3.0  Credit Card  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbis = pd.read_csv('NYC_Taxi_dataset_with_anomalies_bis.csv')\n",
    "dfbis = dfbis.drop(columns=['Unnamed: 0'])\n",
    "dfbis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b3354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing des dates\n",
    "dfbis['pickup_datetime'] = pd.to_datetime(dfbis['pickup_datetime'], errors='coerce')\n",
    "dfbis['dropoff_datetime'] = pd.to_datetime(dfbis['dropoff_datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dc871b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pickup_datetime, dropoff_datetime, pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, trip_distance_miles, fare_amount, passenger_count, payment_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#date inverser\n",
    "\n",
    "dfbis[dfbis['pickup_datetime'] > dfbis['dropoff_datetime']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e340d92e",
   "metadata": {},
   "source": [
    "### Gestion de null dnas les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80509b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime        42\n",
       "dropoff_datetime        0\n",
       "pickup_latitude         0\n",
       "pickup_longitude        0\n",
       "dropoff_latitude        0\n",
       "dropoff_longitude       0\n",
       "trip_distance_miles    40\n",
       "fare_amount            38\n",
       "passenger_count        40\n",
       "payment_type            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15364345",
   "metadata": {},
   "source": [
    "pickup_datetime à notre avis, est un attribut critique. Pour les lignes sans pickup_datetime, on n'a pas de pas de durée fiable, pas de vitesse, pas d’analyse temporelle possible. On a plutot une ambiguïté métier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc365b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['pickup_datetime']).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ffa6b",
   "metadata": {},
   "source": [
    "Pour la colonne ``trip_distance_miles``, nous allons imputer les valeurs manquantes en utilisant la médiane de la vitesse calculée à partir des temps de trajet et distance disponibles. Ensuite faire le produit croisé avec le temps de trajet pour estimer la distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbab81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing des dates\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], errors='coerce')\n",
    "\n",
    "# calculer la vitesse médiane (sur données valides)\n",
    "valid_mask = (\n",
    "    df['trip_distance_miles'].notna() &\n",
    "    df['pickup_datetime'].notna() &\n",
    "    df['dropoff_datetime'].notna()\n",
    ")\n",
    "\n",
    "df['trip_duration_h'] = (\n",
    "    df['dropoff_datetime'] - df['pickup_datetime']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "median_speed_mph = (\n",
    "    df.loc[valid_mask, 'trip_distance_miles'] /\n",
    "    df.loc[valid_mask, 'trip_duration_h']\n",
    ").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72d6ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer la distance manquante\n",
    "mask_nan = df['trip_distance_miles'].isna() & df['trip_duration_h'].notna()\n",
    "\n",
    "df.loc[mask_nan, 'trip_distance_miles'] = (\n",
    "    df.loc[mask_nan, 'trip_duration_h'] * median_speed_mph\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99801db2",
   "metadata": {},
   "source": [
    "Pour l'imputationd de ``passenger_count`` , nous allons imputer par le mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e04f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_mode = df['passenger_count'].mode().iloc[0]\n",
    "df['passenger_count'] = df['passenger_count'].fillna(passenger_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01e41d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime         0\n",
       "dropoff_datetime        0\n",
       "pickup_latitude         0\n",
       "pickup_longitude        0\n",
       "dropoff_latitude        0\n",
       "dropoff_longitude       0\n",
       "trip_distance_miles     0\n",
       "fare_amount            35\n",
       "passenger_count         0\n",
       "payment_type            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"pickup_datetime\", \"dropoff_datetime\", \"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\", \"trip_distance_miles\", \"fare_amount\", \"passenger_count\", \"payment_type\"]]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837ae40",
   "metadata": {},
   "source": [
    "En ce qui concerne l'attribut ``fare_amount``, le type de la colonne est string et contient des caractère spéciaux, nous allons l'imputer une fois ses valeurs numériques extraites et standardisées plus bas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283278b",
   "metadata": {},
   "source": [
    "#### suppression des lignes dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c75ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#les duplicatas\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa7a5ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suppression des duplicatas\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecca98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_improve = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e68b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime        datetime64[ns]\n",
       "dropoff_datetime       datetime64[ns]\n",
       "pickup_latitude               float64\n",
       "pickup_longitude              float64\n",
       "dropoff_latitude              float64\n",
       "dropoff_longitude             float64\n",
       "trip_distance_miles           float64\n",
       "fare_amount                    object\n",
       "passenger_count               float64\n",
       "payment_type                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_improve.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c5d9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pickup_in_future': 0, 'dropoff_in_future': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etat date dans le futur\n",
    "now = pd.Timestamp.now()\n",
    "\n",
    "report = {\n",
    "        \"pickup_in_future\": int((df_to_improve['pickup_datetime'] > now).sum()),\n",
    "        \"dropoff_in_future\": int((df_to_improve['dropoff_datetime'] > now).sum()),\n",
    "    }\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8dff8",
   "metadata": {},
   "source": [
    "On peut constater que nos 40 lignes de dropoff dans le future (detecté dnas l'étape 3) ont été supprimees avec les gestion de valeurs manquantes.\n",
    "\n",
    "Si c'est 40 lignes étaient toujours présentes sur 800 lignes au total, on aurait environ ~5 % avec des dates dans le futur, c’est assez peu dans notre contexte.\n",
    "\n",
    "En ce moment nous procédérons tout simplement à la suppresion de ces lignes. Comme ce qui suit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9547c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = pd.Timestamp.now()\n",
    "\n",
    "df_clean_without_future_date = df_to_improve[\n",
    "    (df_to_improve['pickup_datetime'] <= now) &\n",
    "    (df_to_improve['dropoff_datetime'] <= now)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00b46d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lignes où dropoff est avant pickup\n",
    "inverted_dates = df_clean_without_future_date[\n",
    "    df_clean_without_future_date['dropoff_datetime'] < df_clean_without_future_date['pickup_datetime']\n",
    "]\n",
    "inverted_dates.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca510c31",
   "metadata": {},
   "source": [
    "On n'a pas de date pickup > dropoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122456a",
   "metadata": {},
   "source": [
    "####  Normalize fares -> fare_amount_usd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a25adbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_usd(fare) -> float:\n",
    "    \"\"\"Robust single-value conversion: string with currency symbol or numeric -> USD (float) or np.nan.\"\"\"\n",
    "    try:\n",
    "        if pd.isna(fare):\n",
    "            return np.nan\n",
    "        if isinstance(fare, (int, float, np.number)):\n",
    "            return float(fare)\n",
    "        fare_str = str(fare).strip()\n",
    "        if fare_str == '':\n",
    "            return np.nan\n",
    "        # currency detection\n",
    "        if '€' in fare_str:\n",
    "            return float(fare_str.replace('€', '').strip()) * 1.18\n",
    "        if '£' in fare_str:\n",
    "            return float(fare_str.replace('£', '').strip()) * 1.33\n",
    "        if '¥' in fare_str or 'JPY' in fare_str:\n",
    "            return float(fare_str.replace('¥', '').replace('JPY', '').strip()) * 0.009\n",
    "        if '$' in fare_str:\n",
    "            return float(fare_str.replace('$', '').strip())\n",
    "        # fallback numeric\n",
    "        return round(float(fare_str), 2)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def normalize_fares(df, col = \"fare_amount\", out_col = \"fare_amount_usd\"):\n",
    "    \"\"\"Create numeric USD fare column and report conversion stats.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[out_col] = df[col].apply(convert_to_usd)\n",
    "    \n",
    "    report = {\n",
    "        \"total\": len(df),\n",
    "        \"converted_notnull\": int(df[out_col].notna().sum()),\n",
    "        \"converted_null\": int(df[out_col].isna().sum()),\n",
    "        \"null ou non positif\": int((df[out_col] <= 0).sum())\n",
    "    }\n",
    "    return df, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd419c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 772,\n",
       " 'converted_notnull': 737,\n",
       " 'converted_null': 35,\n",
       " 'null ou non positif': 23}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df, rep_fares = normalize_fares(df_clean_without_future_date, col=\"fare_amount\", out_col=\"fare_amount_usd\")\n",
    "rep_fares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0449d1fd",
   "metadata": {},
   "source": [
    "Sur l'attribut ``fare_amount_usd`` on a 35 valeurs NAN et 23 valeurs null. Ce qui represente environ 7,5% des valeurs de la colonne.\n",
    "\n",
    "Pour l'impution nous allons considerer le tarif median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d210fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  la médiane sur les valeurs valides\n",
    "median_fare = work_df.loc[work_df['fare_amount_usd'] > 0, 'fare_amount_usd'].median()\n",
    "\n",
    "# imputer NaN et valeurs ≤ 0\n",
    "mask_invalid = (work_df['fare_amount_usd'].isna()) | (work_df['fare_amount_usd'] <= 0)\n",
    "\n",
    "work_df.loc[mask_invalid, 'fare_amount_usd'] = median_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb5a5fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime        0\n",
       "dropoff_datetime       0\n",
       "pickup_latitude        0\n",
       "pickup_longitude       0\n",
       "dropoff_latitude       0\n",
       "dropoff_longitude      0\n",
       "trip_distance_miles    0\n",
       "passenger_count        0\n",
       "payment_type           0\n",
       "fare_amount_usd        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df.drop(columns=['fare_amount'], inplace=True)\n",
    "work_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f293ae",
   "metadata": {},
   "source": [
    "#### Gestion des valeurs abérantes constatées dans l'étapes 3\n",
    "\n",
    "On avait noter selon la méthode IQR que 89.68% des valeurs se trouvait dans l'intervalle de valeur acceptable (avant biensur les suppressions de lignes faites plus haut).\n",
    "Pour donc gerer les valeurs aberantes ici qui sont >10%, nous allons procédé à limputation par la valeur médianne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f6be9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'outliers avant : 36\n",
      "Nombre d'outliers après : 0\n"
     ]
    }
   ],
   "source": [
    "# Les valeurs seuil \n",
    "\n",
    "Q1 = work_df['fare_amount_usd'].quantile(0.25)\n",
    "Q3 = work_df['fare_amount_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# impute par la valeur medianne\n",
    "median_fare = work_df['fare_amount_usd'].median()\n",
    "\n",
    "outliers = work_df[\n",
    "    (work_df['fare_amount_usd'] < lower_bound) | \n",
    "    (work_df['fare_amount_usd'] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"Nombre d'outliers avant : {len(outliers)}\")\n",
    "\n",
    "# Remplacer les outliers par la médiane\n",
    "work_df['fare_amount_usd'] = work_df['fare_amount_usd'].mask(\n",
    "    (work_df['fare_amount_usd'] < lower_bound) | (work_df['fare_amount_usd'] > upper_bound),\n",
    "    median_fare\n",
    ")\n",
    "\n",
    "outliers = work_df[\n",
    "    (work_df['fare_amount_usd'] < lower_bound) | \n",
    "    (work_df['fare_amount_usd'] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"Nombre d'outliers après : {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9c9f",
   "metadata": {},
   "source": [
    "On constate que la suppresion des lignes a fait baissé le nombre de doutliers de fare_amount_usd dans nos données. L'imputation ici par la valeur médianne reste acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9db27",
   "metadata": {},
   "source": [
    "#### Gestion des coordonnées hors NYC\n",
    "Dans l'étape 03, on avait pu constater la présence de coordonnées géographiques hors de NYC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f83aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de coordonnées(pickup ou dropoff) invalides: 95 -- total lignes: 772\n"
     ]
    }
   ],
   "source": [
    "# Approximation coordonnées ville de new York\n",
    "nyc_min_latitude = 40.5\n",
    "nyc_max_latitude = 40.92   \n",
    "nyc_min_longitude = -74.26 \n",
    "nyc_max_longitude = -73.7\n",
    "invalid_pickup = work_df[\n",
    "    (work_df['pickup_latitude'] < nyc_min_latitude) | (work_df['pickup_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['pickup_longitude'] < nyc_min_longitude) | (work_df['pickup_longitude'] > nyc_max_longitude)\n",
    "]\n",
    "invalid_pickup.shape[0]\n",
    "invalid_dropoff = work_df[\n",
    "    (work_df['dropoff_latitude'] < nyc_min_latitude) | (work_df['dropoff_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['dropoff_longitude'] < nyc_min_longitude) | (work_df['dropoff_longitude'] > nyc_max_longitude)\n",
    "]\n",
    "invalid_dropoff.shape[0]\n",
    "\n",
    "print(f\"nombre de coordonnées(pickup ou dropoff) invalides: {invalid_pickup.shape[0] + invalid_dropoff.shape[0]} -- total lignes: {work_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d4bd9",
   "metadata": {},
   "source": [
    "On a environ 10% des valeurs qui ne sont pas à NYC pour (pickup et dropoff compris),\n",
    "\n",
    "Pour l'imputation nous allons remplacer les valeurs par les coordonnées mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3f18cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de coordonnées(pickup ou dropoff) invalides après imputation: 0 -- total lignes: 772\n"
     ]
    }
   ],
   "source": [
    "# on remplace les coordonnées invalides par le mode des coordonnées valides\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour pcickup et impute les invalides\n",
    "valid_pickup_lat_mode = work_df.loc[\n",
    "    (work_df['pickup_latitude'] >= nyc_min_latitude) & (work_df['pickup_latitude'] <= nyc_max_latitude),\n",
    "    'pickup_latitude'\n",
    "].mode()[0]\n",
    "work_df['pickup_latitude'] = work_df['pickup_latitude'].apply(\n",
    "    lambda x: valid_pickup_lat_mode if (x < nyc_min_latitude or x > nyc_max_latitude) else x\n",
    ")\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour pcickup et impute les invalides\n",
    "valid_pickup_lon_mode = work_df.loc[\n",
    "    (work_df['pickup_longitude'] >= nyc_min_longitude) & (work_df['pickup_longitude'] <= nyc_max_longitude),\n",
    "    'pickup_longitude'\n",
    "].mode()[0]\n",
    "work_df['pickup_longitude'] = work_df['pickup_longitude'].apply(\n",
    "    lambda x: valid_pickup_lon_mode if (x < nyc_min_longitude or x > nyc_max_longitude) else x\n",
    ")\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour dropoff et impute les invalides\n",
    "valid_dropoff_lat_mode = work_df.loc[\n",
    "    (work_df['dropoff_latitude'] >= nyc_min_latitude) & (work_df['dropoff_latitude'] <= nyc_max_latitude),\n",
    "    'dropoff_latitude'\n",
    "].mode()[0]\n",
    "work_df['dropoff_latitude'] = work_df['dropoff_latitude'].apply(\n",
    "    lambda x: valid_dropoff_lat_mode if (x < nyc_min_latitude or x > nyc_max_latitude) else x\n",
    ")\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour dropoff et impute les invalides\n",
    "valid_dropoff_lon_mode = work_df.loc[\n",
    "    (work_df['dropoff_longitude'] >= nyc_min_longitude) & (work_df['dropoff_longitude'] <= nyc_max_longitude),\n",
    "    'dropoff_longitude'\n",
    "].mode()[0]\n",
    "work_df['dropoff_longitude'] = work_df['dropoff_longitude'].apply(\n",
    "    lambda x: valid_dropoff_lon_mode if (x < nyc_min_longitude or x > nyc_max_longitude) else x\n",
    ")\n",
    "\n",
    "# re-evaluation des coordonnées invalides\n",
    "invalid_pickup = work_df[\n",
    "    (work_df['pickup_latitude'] < nyc_min_latitude) | (work_df['pickup_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['pickup_longitude'] < nyc_min_longitude) | (work_df['pickup_longitude'] > nyc_max_longitude)\n",
    "]\n",
    "invalid_pickup.shape[0]\n",
    "invalid_dropoff = work_df[\n",
    "    (work_df['dropoff_latitude'] < nyc_min_latitude) | (work_df['dropoff_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['dropoff_longitude'] < nyc_min_longitude) | (work_df['dropoff_longitude'] > nyc_max_longitude)\n",
    "]   \n",
    "invalid_dropoff.shape[0]\n",
    "print(f\"nombre de coordonnées(pickup ou dropoff) invalides après imputation: {invalid_pickup.shape[0] + invalid_dropoff.shape[0]} -- total lignes: {work_df.shape[0]}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212086c",
   "metadata": {},
   "source": [
    "Toutes les valeurs (coordonnées gps) invalides ont été imputé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144fd74",
   "metadata": {},
   "source": [
    "#### Payment_type\n",
    "\n",
    "En faisant le data profiling du dataset à l'étape 3 on avait pu constater la présence de valeurs avec la même sémantique mais orthographié, ou exprimé par des string différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2d0135d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit Card', 'Unknown', 'Cash', ' CREDIT CARD ', 'credit card',\n",
       "       'cash', 'Dispute', 'No Charge', 'CREDIT CARD', 'Disagreement'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df['payment_type'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a70cdf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['credit_card', 'unknown', 'cash', 'dispute', 'no_charge'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uniformiser les valeurs\n",
    "work_df['payment_type'] = work_df['payment_type'].str.strip().str.lower()\n",
    "\n",
    "#  regroupons\n",
    "work_df['payment_type'] = work_df['payment_type'].replace({\n",
    "    'credit card': 'credit_card',\n",
    "    'cash': 'cash',\n",
    "    'unknown': 'unknown',\n",
    "    'dispute': 'dispute',\n",
    "    'no charge': 'no_charge',\n",
    "    'disagreement': 'dispute'  # Exemple de regroupement\n",
    "})\n",
    "\n",
    "work_df['payment_type'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931931f",
   "metadata": {},
   "source": [
    "### Gestion valeurs aberant sur le tuples ('pickup_datetime', 'dropoff_datetime', 'trip_distance_miles')\n",
    "\n",
    "Dans l'étape de l'assessmen, on avait trouvé des valeurs aberantes en calculant la vitesse moyenne de certains trajet. Des vitesses qui allait jusqu'à 120 mph (soit près de 200km/h)\n",
    "\n",
    "On avait donc fixé comme seuil de vitesse min = 0.5 mph (circulation dense, embouteillage) et\n",
    "max = 60 mph (environ 100km/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ec11998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sur la vitesse en utilisant les champs pickup_datetime, dropoff_datetime et trip_distance_miles\n",
    "def calculate_speed(row):\n",
    "    try:\n",
    "        pickup_time = pd.to_datetime(row['pickup_datetime'])\n",
    "        dropoff_time = pd.to_datetime(row['dropoff_datetime'])\n",
    "        trip_distance = row['trip_distance_miles']\n",
    "        \n",
    "        if pd.isna(pickup_time) or pd.isna(dropoff_time) or trip_distance <= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        trip_duration = (dropoff_time - pickup_time).total_seconds() / 3600  # durée en heures\n",
    "        if trip_duration <= 0:\n",
    "            return np.nan\n",
    "        \n",
    "        speed = trip_distance / trip_duration  # vitesse en miles par heure\n",
    "        return speed\n",
    "    except Exception as e:\n",
    "        return np.nan\n",
    "    \n",
    "work_df['speed_mph'] = work_df.apply(calculate_speed, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fd4119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de trajets avec vitesse invalide: 19 sur un total de 772 trajets.\n"
     ]
    }
   ],
   "source": [
    "min_speed_threshold = 0.5  # mph\n",
    "max_speed_threshold = 60  # mph\n",
    "\n",
    "invalid_speed = work_df[\n",
    "    (work_df['speed_mph'] < min_speed_threshold) | (work_df['speed_mph'] > max_speed_threshold)\n",
    "]\n",
    "print(f\"Nombre de trajets avec vitesse invalide: {len(invalid_speed)} sur un total de {len(work_df)} trajets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf43437",
   "metadata": {},
   "source": [
    "On a environ 2% des trajets qui ont des vitesses invalides. Pour 2% nous allons tout simplement laisser tomber ces lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3129025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtrer les lignes avec trajet \n",
    "df_improve = work_df[\n",
    "    (work_df['speed_mph'] >= min_speed_threshold) & (work_df['speed_mph'] <= max_speed_threshold)\n",
    "]\n",
    "df_improve.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c707d17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_improved = df_improve[[\"pickup_datetime\", \"dropoff_datetime\", \"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\", \"trip_distance_miles\", \"fare_amount_usd\", \"passenger_count\", \"payment_type\"]]\n",
    "df_improved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ee50ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_improved.to_csv('NYC_Taxi_dataset_improved.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
