{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edba2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3f4a25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-20 17:27:00</td>\n",
       "      <td>2023-02-20 17:49:00</td>\n",
       "      <td>40.808941</td>\n",
       "      <td>-73.914482</td>\n",
       "      <td>40.807336</td>\n",
       "      <td>-73.905270</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.84$</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28 19:41:00</td>\n",
       "      <td>2023-02-28 20:07:00</td>\n",
       "      <td>40.685842</td>\n",
       "      <td>-73.855449</td>\n",
       "      <td>40.663358</td>\n",
       "      <td>-73.826745</td>\n",
       "      <td>4.02</td>\n",
       "      <td>15.6£</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-14 08:37:00</td>\n",
       "      <td>2023-02-14 09:07:00</td>\n",
       "      <td>40.668055</td>\n",
       "      <td>-74.045050</td>\n",
       "      <td>40.642572</td>\n",
       "      <td>-74.055617</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2192.65¥</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-16 23:54:00</td>\n",
       "      <td>2023-01-17 00:40:00</td>\n",
       "      <td>40.765394</td>\n",
       "      <td>-73.753324</td>\n",
       "      <td>40.775285</td>\n",
       "      <td>-73.775441</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-11 01:16:00</td>\n",
       "      <td>2023-02-11 01:35:00</td>\n",
       "      <td>40.815841</td>\n",
       "      <td>-73.727328</td>\n",
       "      <td>40.836115</td>\n",
       "      <td>-73.746976</td>\n",
       "      <td>3.11</td>\n",
       "      <td>13.7€</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pickup_datetime     dropoff_datetime  pickup_latitude  \\\n",
       "0  2023-02-20 17:27:00  2023-02-20 17:49:00        40.808941   \n",
       "1  2023-02-28 19:41:00  2023-02-28 20:07:00        40.685842   \n",
       "2  2023-02-14 08:37:00  2023-02-14 09:07:00        40.668055   \n",
       "3  2023-01-16 23:54:00  2023-01-17 00:40:00        40.765394   \n",
       "4  2023-02-11 01:16:00  2023-02-11 01:35:00        40.815841   \n",
       "\n",
       "   pickup_longitude  dropoff_latitude  dropoff_longitude  trip_distance_miles  \\\n",
       "0        -73.914482         40.807336         -73.905270                 1.03   \n",
       "1        -73.855449         40.663358         -73.826745                 4.02   \n",
       "2        -74.045050         40.642572         -74.055617                 3.04   \n",
       "3        -73.753324         40.775285         -73.775441                 2.67   \n",
       "4        -73.727328         40.836115         -73.746976                 3.11   \n",
       "\n",
       "  fare_amount  passenger_count payment_type  \n",
       "0       5.84$              5.0  Credit Card  \n",
       "1       15.6£              4.0      Unknown  \n",
       "2    2192.65¥              5.0  Credit Card  \n",
       "3           0              4.0  Credit Card  \n",
       "4       13.7€              3.0  Credit Card  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NYC_Taxi_dataset_with_anomalies.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1a94318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#les duplicatas\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283278b",
   "metadata": {},
   "source": [
    "#### #suppression des lignes dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa7a5ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suppression des duplicatas\n",
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecca98d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_improve = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e68b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime         object\n",
       "dropoff_datetime        object\n",
       "pickup_latitude        float64\n",
       "pickup_longitude       float64\n",
       "dropoff_latitude       float64\n",
       "dropoff_longitude      float64\n",
       "trip_distance_miles    float64\n",
       "fare_amount             object\n",
       "passenger_count        float64\n",
       "payment_type            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_improve.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cc0b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\"parse all attributes that look like dates to datetime format\"'''\n",
    "date_columns = ['pickup_datetime', 'dropoff_datetime']\n",
    "for col in date_columns:\n",
    "    df_to_improve[col] = pd.to_datetime(df_to_improve[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c5d9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pickup_parsed': 772,\n",
       " 'dropoff_parsed': 812,\n",
       " 'pickup_in_future': 0,\n",
       " 'dropoff_in_future': 38}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etat date parser\n",
    "now = pd.Timestamp.now()\n",
    "\n",
    "report = {\n",
    "        \"pickup_parsed\": int(df_to_improve['pickup_datetime'].notna().sum()),\n",
    "        \"dropoff_parsed\": int(df_to_improve['dropoff_datetime'].notna().sum()),\n",
    "        \"pickup_in_future\": int((df_to_improve['pickup_datetime'] > now).sum()),\n",
    "        \"dropoff_in_future\": int((df_to_improve['dropoff_datetime'] > now).sum()),\n",
    "    }\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39020a53",
   "metadata": {},
   "source": [
    "On a 40 lignes sur 800 (~5 %) avec des dates dans le futur, c’est assez peu dans notre contexte,\n",
    "nous allons procédé à la suppresion de ces lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9547c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = pd.Timestamp.now()\n",
    "\n",
    "df_clean_without_future_date = df_to_improve[\n",
    "    (df_to_improve['pickup_datetime'] <= now) &\n",
    "    (df_to_improve['dropoff_datetime'] <= now)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00b46d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lignes où dropoff est avant pickup\n",
    "inverted_dates = df_clean_without_future_date[\n",
    "    df_clean_without_future_date['dropoff_datetime'] < df_clean_without_future_date['pickup_datetime']\n",
    "]\n",
    "inverted_dates.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca510c31",
   "metadata": {},
   "source": [
    "On n'a pas de date pickup > dropoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122456a",
   "metadata": {},
   "source": [
    "####  Normalize fares -> fare_amount_usd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25adbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_usd(fare) -> float:\n",
    "    \"\"\"Robust single-value conversion: string with currency symbol or numeric -> USD (float) or np.nan.\"\"\"\n",
    "    try:\n",
    "        if pd.isna(fare):\n",
    "            return np.nan\n",
    "        if isinstance(fare, (int, float, np.number)):\n",
    "            return float(fare)\n",
    "        fare_str = str(fare).strip()\n",
    "        if fare_str == '':\n",
    "            return np.nan\n",
    "        # currency detection\n",
    "        if '€' in fare_str:\n",
    "            return float(fare_str.replace('€', '').strip()) * 1.18\n",
    "        if '£' in fare_str:\n",
    "            return float(fare_str.replace('£', '').strip()) * 1.33\n",
    "        if '¥' in fare_str or 'JPY' in fare_str:\n",
    "            return float(fare_str.replace('¥', '').replace('JPY', '').strip()) * 0.009\n",
    "        if '$' in fare_str:\n",
    "            return float(fare_str.replace('$', '').strip())\n",
    "        # fallback numeric\n",
    "        return float(fare_str)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def normalize_fares(df: pd.DataFrame, col: str = \"fare_amount\", out_col: str = \"fare_amount_usd\"):\n",
    "    \"\"\"Create numeric USD fare column and report conversion stats.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[out_col] = df[col].apply(convert_to_usd)\n",
    "    \n",
    "    report = {\n",
    "        \"total\": len(df),\n",
    "        \"converted_notnull\": int(df[out_col].notna().sum()),\n",
    "        \"converted_null\": int(df[out_col].isna().sum()),\n",
    "        \"non_positive\": int((df[out_col] <= 0).sum())\n",
    "    }\n",
    "    return df, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd419c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 772,\n",
       " 'converted_notnull': 737,\n",
       " 'converted_null': 35,\n",
       " 'non_positive': 23}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df, rep_fares = normalize_fares(df_clean_without_future_date, col=\"fare_amount\", out_col=\"fare_amount_usd\")\n",
    "rep_fares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee738d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance_miles</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-20 17:27:00</td>\n",
       "      <td>2023-02-20 17:49:00</td>\n",
       "      <td>40.808941</td>\n",
       "      <td>-73.914482</td>\n",
       "      <td>40.807336</td>\n",
       "      <td>-73.905270</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.84$</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>5.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28 19:41:00</td>\n",
       "      <td>2023-02-28 20:07:00</td>\n",
       "      <td>40.685842</td>\n",
       "      <td>-73.855449</td>\n",
       "      <td>40.663358</td>\n",
       "      <td>-73.826745</td>\n",
       "      <td>4.02</td>\n",
       "      <td>15.6£</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20.74800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-14 08:37:00</td>\n",
       "      <td>2023-02-14 09:07:00</td>\n",
       "      <td>40.668055</td>\n",
       "      <td>-74.045050</td>\n",
       "      <td>40.642572</td>\n",
       "      <td>-74.055617</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2192.65¥</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>19.73385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-16 23:54:00</td>\n",
       "      <td>2023-01-17 00:40:00</td>\n",
       "      <td>40.765394</td>\n",
       "      <td>-73.753324</td>\n",
       "      <td>40.775285</td>\n",
       "      <td>-73.775441</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-11 01:16:00</td>\n",
       "      <td>2023-02-11 01:35:00</td>\n",
       "      <td>40.815841</td>\n",
       "      <td>-73.727328</td>\n",
       "      <td>40.836115</td>\n",
       "      <td>-73.746976</td>\n",
       "      <td>3.11</td>\n",
       "      <td>13.7€</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>16.16600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  pickup_latitude  pickup_longitude  \\\n",
       "0 2023-02-20 17:27:00 2023-02-20 17:49:00        40.808941        -73.914482   \n",
       "1 2023-02-28 19:41:00 2023-02-28 20:07:00        40.685842        -73.855449   \n",
       "2 2023-02-14 08:37:00 2023-02-14 09:07:00        40.668055        -74.045050   \n",
       "3 2023-01-16 23:54:00 2023-01-17 00:40:00        40.765394        -73.753324   \n",
       "4 2023-02-11 01:16:00 2023-02-11 01:35:00        40.815841        -73.727328   \n",
       "\n",
       "   dropoff_latitude  dropoff_longitude  trip_distance_miles fare_amount  \\\n",
       "0         40.807336         -73.905270                 1.03       5.84$   \n",
       "1         40.663358         -73.826745                 4.02       15.6£   \n",
       "2         40.642572         -74.055617                 3.04    2192.65¥   \n",
       "3         40.775285         -73.775441                 2.67           0   \n",
       "4         40.836115         -73.746976                 3.11       13.7€   \n",
       "\n",
       "   passenger_count payment_type  fare_amount_usd  \n",
       "0              5.0  Credit Card          5.84000  \n",
       "1              4.0      Unknown         20.74800  \n",
       "2              5.0  Credit Card         19.73385  \n",
       "3              4.0  Credit Card          0.00000  \n",
       "4              3.0  Credit Card         16.16600  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185cbef",
   "metadata": {},
   "source": [
    "Pour traiter les valeurs fare_amount_usd (35) nulls et negative(23), nous allons les remplacer par la valeurs medians ces lignes on (35+23)/772 > 5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23355ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing or non-positive fares with median of positive fares\n",
    "\n",
    "median_fare = work_df.loc[work_df['fare_amount_usd'] > 0, 'fare_amount_usd'].median()\n",
    "work_df['fare_amount_usd'] = work_df['fare_amount_usd'].apply(lambda x: median_fare if pd.isna(x) or x <= 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c75aabba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valeur null ou negative \n",
    "work_df[work_df['fare_amount_usd'] <= 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f293ae",
   "metadata": {},
   "source": [
    "#### Gestion des valeurs abérantes constatées dans l'étapes 3\n",
    "\n",
    "On avait noter selon la méthode IQR que 89.68% des valeurs se trouvait dans l'intervalle de valeur acceptable (avant biensur les suppressions de lignes faites plus haut).\n",
    "Pour donc gerer les valeurs aberantes ici qui sont >10%, nous allons procédé à limputation par la valeur médianne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f6be9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'outliers avant : 36\n",
      "Nombre d'outliers après : 0\n"
     ]
    }
   ],
   "source": [
    "# Les valeurs seuil \n",
    "\n",
    "Q1 = work_df['fare_amount_usd'].quantile(0.25)\n",
    "Q3 = work_df['fare_amount_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# impute par la valeur medianne\n",
    "median_fare = work_df['fare_amount_usd'].median()\n",
    "\n",
    "outliers = work_df[\n",
    "    (work_df['fare_amount_usd'] < lower_bound) | \n",
    "    (work_df['fare_amount_usd'] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"Nombre d'outliers avant : {len(outliers)}\")\n",
    "\n",
    "# Remplacer les outliers par la médiane\n",
    "work_df['fare_amount_usd'] = work_df['fare_amount_usd'].mask(\n",
    "    (work_df['fare_amount_usd'] < lower_bound) | (work_df['fare_amount_usd'] > upper_bound),\n",
    "    median_fare\n",
    ")\n",
    "\n",
    "outliers = work_df[\n",
    "    (work_df['fare_amount_usd'] < lower_bound) | \n",
    "    (work_df['fare_amount_usd'] > upper_bound)\n",
    "]\n",
    "\n",
    "print(f\"Nombre d'outliers après : {len(outliers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9c9f",
   "metadata": {},
   "source": [
    "On constate que la suppresion des lignes a fait baissé le nombre de doutliers de fare_amount_usd dans nos données. L'imputation ici par la valeur médianne reste acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9db27",
   "metadata": {},
   "source": [
    "#### Gestion des coordonnées hors NYC\n",
    "Dans l'étape 03, on avait pu constater la présence de coordonnées géographiques hors de NYC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f83aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de coordonnées(pickup ou dropoff) invalides: 95 -- total lignes: 772\n"
     ]
    }
   ],
   "source": [
    "# Approximation coordonnées ville de new York\n",
    "nyc_min_latitude = 40.5\n",
    "nyc_max_latitude = 40.92   \n",
    "nyc_min_longitude = -74.26 \n",
    "nyc_max_longitude = -73.7\n",
    "invalid_pickup = work_df[\n",
    "    (work_df['pickup_latitude'] < nyc_min_latitude) | (work_df['pickup_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['pickup_longitude'] < nyc_min_longitude) | (work_df['pickup_longitude'] > nyc_max_longitude)\n",
    "]\n",
    "invalid_pickup.shape[0]\n",
    "invalid_dropoff = work_df[\n",
    "    (work_df['dropoff_latitude'] < nyc_min_latitude) | (work_df['dropoff_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['dropoff_longitude'] < nyc_min_longitude) | (work_df['dropoff_longitude'] > nyc_max_longitude)\n",
    "]\n",
    "invalid_dropoff.shape[0]\n",
    "\n",
    "print(f\"nombre de coordonnées(pickup ou dropoff) invalides: {invalid_pickup.shape[0] + invalid_dropoff.shape[0]} -- total lignes: {work_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d4bd9",
   "metadata": {},
   "source": [
    "On a environ 10% des valeurs qui ne sont pas à NYC pour (pickup et dropoff compris),\n",
    "\n",
    "Pour l'imputation nous allons remplacer les valeurs par les coordonnées mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3f18cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de coordonnées(pickup ou dropoff) invalides après imputation: 0 -- total lignes: 772\n"
     ]
    }
   ],
   "source": [
    "# on remplace les coordonnées invalides par le mode des coordonnées valides\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour pcickup et impute les invalides\n",
    "valid_pickup_lat_mode = work_df.loc[\n",
    "    (work_df['pickup_latitude'] >= nyc_min_latitude) & (work_df['pickup_latitude'] <= nyc_max_latitude),\n",
    "    'pickup_latitude'\n",
    "].mode()[0]\n",
    "work_df['pickup_latitude'] = work_df['pickup_latitude'].apply(\n",
    "    lambda x: valid_pickup_lat_mode if (x < nyc_min_latitude or x > nyc_max_latitude) else x\n",
    ")\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour pcickup et impute les invalides\n",
    "valid_pickup_lon_mode = work_df.loc[\n",
    "    (work_df['pickup_longitude'] >= nyc_min_longitude) & (work_df['pickup_longitude'] <= nyc_max_longitude),\n",
    "    'pickup_longitude'\n",
    "].mode()[0]\n",
    "work_df['pickup_longitude'] = work_df['pickup_longitude'].apply(\n",
    "    lambda x: valid_pickup_lon_mode if (x < nyc_min_longitude or x > nyc_max_longitude) else x\n",
    ")\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour dropoff et impute les invalides\n",
    "valid_dropoff_lat_mode = work_df.loc[\n",
    "    (work_df['dropoff_latitude'] >= nyc_min_latitude) & (work_df['dropoff_latitude'] <= nyc_max_latitude),\n",
    "    'dropoff_latitude'\n",
    "].mode()[0]\n",
    "work_df['dropoff_latitude'] = work_df['dropoff_latitude'].apply(\n",
    "    lambda x: valid_dropoff_lat_mode if (x < nyc_min_latitude or x > nyc_max_latitude) else x\n",
    ")\n",
    "\n",
    "# on recupere le mode des coordonnees valides pour dropoff et impute les invalides\n",
    "valid_dropoff_lon_mode = work_df.loc[\n",
    "    (work_df['dropoff_longitude'] >= nyc_min_longitude) & (work_df['dropoff_longitude'] <= nyc_max_longitude),\n",
    "    'dropoff_longitude'\n",
    "].mode()[0]\n",
    "work_df['dropoff_longitude'] = work_df['dropoff_longitude'].apply(\n",
    "    lambda x: valid_dropoff_lon_mode if (x < nyc_min_longitude or x > nyc_max_longitude) else x\n",
    ")\n",
    "\n",
    "# re-evaluation des coordonnées invalides\n",
    "invalid_pickup = work_df[\n",
    "    (work_df['pickup_latitude'] < nyc_min_latitude) | (work_df['pickup_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['pickup_longitude'] < nyc_min_longitude) | (work_df['pickup_longitude'] > nyc_max_longitude)\n",
    "]\n",
    "invalid_pickup.shape[0]\n",
    "invalid_dropoff = work_df[\n",
    "    (work_df['dropoff_latitude'] < nyc_min_latitude) | (work_df['dropoff_latitude'] > nyc_max_latitude) |\n",
    "    (work_df['dropoff_longitude'] < nyc_min_longitude) | (work_df['dropoff_longitude'] > nyc_max_longitude)\n",
    "]   \n",
    "invalid_dropoff.shape[0]\n",
    "print(f\"nombre de coordonnées(pickup ou dropoff) invalides après imputation: {invalid_pickup.shape[0] + invalid_dropoff.shape[0]} -- total lignes: {work_df.shape[0]}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4212086c",
   "metadata": {},
   "source": [
    "Toutes les valeurs (coordonnées gps) invalides ont été imputé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144fd74",
   "metadata": {},
   "source": [
    "#### Payment_type\n",
    "\n",
    "En faisant le data profiling du dataset à l'étape 3 on avait pu constater la présence de valeurs avec la même sémantique mais orthographié, ou exprimé par des string différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2d0135d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit Card', 'Unknown', 'Cash', ' CREDIT CARD ', 'credit card',\n",
       "       'cash', 'Dispute', 'No Charge', 'CREDIT CARD', 'Disagreement'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_df['payment_type'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cdf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['credit_card', 'unknown', 'cash', 'dispute', 'no_charge'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uniformiser les valeurs\n",
    "work_df['payment_type'] = work_df['payment_type'].str.strip().str.lower()\n",
    "\n",
    "#  regroupons\n",
    "work_df['payment_type'] = work_df['payment_type'].replace({\n",
    "    'credit card': 'credit_card',\n",
    "    'cash': 'cash',\n",
    "    'unknown': 'unknown',\n",
    "    'dispute': 'dispute',\n",
    "    'no charge': 'no_charge',\n",
    "    'disagreement': 'dispute'  # Exemple de regroupement\n",
    "})\n",
    "\n",
    "work_df['payment_type'].unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
